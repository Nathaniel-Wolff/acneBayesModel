{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dfa384b",
   "metadata": {},
   "source": [
    "The purpose of the notebook is the following:\n",
    "\n",
    "0) Receive a dataset containing an aggregate dataframe with acne severities for a group of patients\n",
    "1) Parse the data and seperate it into one dataframes per patient. Raw acne severities are converted into % change in acne severity relative to average baseline. The average baseline is computed dynamically for each patient.\n",
    "2) Add a treatment history metadata column to each patient dataframe in the form ( (Treatment a1, Day 1), ..., (Treatment an, Day i)) where n is the index of a given treatment in the full history.\n",
    "3) Produce the distribution of % changes in acne severity over all histories and patients. Fit a kernel density estimate and display it for visual inspection.\n",
    "4) (Assumes a bimodal distribution); Optimize the KDE for local maxima and saddle point; find quantiles corresponding to local maxima and saddle points. Each quantile defines an acne severity change state. **In progress: dynamic decision of state number.*\n",
    "5) Assign an acne severity change state to each acne severity entry for all patient dataframes.       \n",
    "6) (Assumes a Dirichlet prior distribution for acne severity change probabilities) Calculate posterior distributions of acne severity change states for each consecutive treatment history. Plot each posterior as a striped heatmap for visual inspection. **In progress: dynamic decision of prior.*\n",
    "8) Calculate Kullback-Leibler Divergence between consecutive treatment history posteriors. Plot stepwise and cumulative KL Divergence for visual inspection. cumulative KL Divergence is interpreted as cumulative information gain from changing acne severity state distributions. \n",
    "9) Approximate concavity of cumulative KL Divergence vs. treatment history ordinal curve; use user provided percentile cutoff to define inflection point concavity threshold.\n",
    "10) Partion cumulative KL Divergence array between inflection points. Prevents regression model overfitting by checking if slope difference between adjacent inflection points exceeds user provided threshold. **In progress: further pruning of inflection points with AIC/BIC.*\n",
    "11) Fits linear regression model to each cumulative KL Divergence sublist; returns slope of each. Quantifies extent of change in acne severity state distribution pairwise. **In progress: Plotting treatment history vs. inflection point slope to reveal treatments responsible for greatest changes.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2d4c8b-312d-4177-a37d-5caa2a0cf10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.12/site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.12/site-packages (2.2.4)\n",
      "Requirement already satisfied: seaborn in /opt/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: statsmodels in /opt/miniconda3/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/miniconda3/lib/python3.12/site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "#virtual environment \n",
    "! pip install matplotlib pandas scipy numpy seaborn scikit-learn statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83b41d1-f7c2-4a97-948a-db0f878d1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import matplotlib\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle as rect\n",
    "from itertools import permutations\n",
    "from colorsys import rgb_to_hls, hls_to_rgb\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from matplotlib.cm import viridis\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import dirichlet \n",
    "from scipy.stats import beta\n",
    "from scipy.special import gammaln, psi\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993ddf9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def seperate_patients(raw_data):\n",
    "    \"\"\"Function that separates the raw dataframe via the following:\n",
    "    1) Constructs an array tracking where the original date (2018-01-01) recurs.\n",
    "    2) Uses that array to split raw_data into seperate dataframes.\n",
    "    \"\"\"\n",
    "    #splitting data into different patients using leftmost column index (this is an assumption however)\n",
    "    seperatePatientsIndices = list(raw_data.index[raw_data[\"date\"] == \"2018-01-01\"])\n",
    "    seperatePatientsIndices.append(len(raw_data))\n",
    "\n",
    "    #checking to see if, after the same number of days in all dataframes, treatment of some sort was introduced\n",
    "    #verifies that on day 29 \n",
    "    #then adds the days each additional treatment was added after the fact (turns out they are all the same too)\n",
    "    allPatientsIntroDays = []\n",
    "    \n",
    "    #seperating single dataframe into list of dataframes for each patient\n",
    "    startIndex = 0\n",
    "    seperatePatientsDFs = []\n",
    "    for endIndex in seperatePatientsIndices[1:]:\n",
    "        seperatePatientsDFs.append(raw_data[startIndex:endIndex])\n",
    "        startIndex = endIndex\n",
    "     \n",
    "    for seperatePatientDF in seperatePatientsDFs:\n",
    "        treatmentIntroDays =  []\n",
    "        currentTreatment = seperatePatientDF[\"treatment\"].iloc[0]\n",
    "          \n",
    "        for lineIndex in range(1,len(seperatePatientDF)): \n",
    "            if seperatePatientDF[\"treatment\"].iloc[lineIndex] != currentTreatment:\n",
    "                treatmentIntroDays.append([currentTreatment, \"end day is\", lineIndex])\n",
    "                currentTreatment  = seperatePatientDF[\"treatment\"].iloc[lineIndex]\n",
    "                \n",
    "                \n",
    "        #remembering the end day of the last treatment and appending to the list\n",
    "        lastTreatment  = seperatePatientDF[\"treatment\"].iloc[len(seperatePatientDF)-1]\n",
    "        treatmentIntroDays.append( [lastTreatment, \"end day is\", len(seperatePatientDF) - 1 ] )\n",
    "         \n",
    "        allPatientsIntroDays.append(treatmentIntroDays)\n",
    "        \n",
    "    return seperatePatientsDFs, allPatientsIntroDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dcf792a-8822-4a2c-820e-73f2f3c77240",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def linear_generator_starting_colors(number_treatments, base_colormap = \"viridis\"):\n",
    "    \"\"\"A helper function for display_plots_of_dataset below. Generates n RGB tuples on a linear scale, given the number of treatments.\n",
    "    Each of these is used as a starting point for a regular map of treatments by day and a blended heatmap of treatments by day, with\n",
    "    lower lightness for each consecutive day of the same treatment, blended with the last color corresponding to the days of the\n",
    "    previous treatments.\"\"\"\n",
    "\n",
    "    #scaled_first_color = tuple(float(x/255) for x in first_color)\n",
    "    #scaled_last_color = tuple(float(x/255) for x in last_color)\n",
    "    \n",
    "    #c_start = np.array(scaled_first_color)\n",
    "    #c_end = np.array(scaled_last_color)\n",
    "\n",
    "    cmap = plt.get_cmap(base_colormap)\n",
    "    default_colors = [cmap(i / (number_treatments - 1))[:3] for i in range(number_treatments)]\n",
    "    return default_colors\n",
    "    \n",
    "    # decimal_returned_tuples = [tuple(c_start + (i / (number_treatments - 1)) * (c_end - c_start)) for i in range(number_treatments)]\n",
    "    # RGB_returned_tuples = []\n",
    "    # RGB_returned_tuples_codes = []\n",
    "    # for raw_tuple in decimal_returned_tuples:\n",
    "    #     rescaled_tuple_as_hex_code = '#%02x%02x%02x' % tuple(int(255*x) for x in raw_tuple)\n",
    "    #     RGB_raw_tuple = tuple(int(255*x) for x in raw_tuple) #unused now\n",
    "    #     RGB_returned_tuples.append(raw_tuple)\n",
    "    #     RGB_returned_tuples_codes.append(rescaled_tuple_as_hex_code)\n",
    "        \n",
    "    # return RGB_returned_tuples, RGB_returned_tuples_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4d89ae-b7d1-4874-bf71-17a4dfa44207",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def blend_old_and_new_color(old_color, new_color, alpha):\n",
    "    \"\"\"Another function used by display_plots_of_dataset. Simply blends 2 colors with a given alpha value.\"\"\"\n",
    "     # normalize both old and new colors into decimals\n",
    "    o = np.array(old_color)\n",
    "    n = np.array(new_color)\n",
    "\n",
    "    \n",
    "    o_h, o_l, o_s = rgb_to_hls(*o)\n",
    "    n_h, n_l, n_s = rgb_to_hls(*n)\n",
    "    \n",
    "    # circular interpolation of hue for more effective blending\n",
    "    hue_diff = ((n_h - o_h + 0.5) % 1.0) - 0.5\n",
    "    blended_h = (o_h + alpha * hue_diff) % 1.0\n",
    "    blended_l = (1 - alpha) * o_l + alpha * n_l\n",
    "    blended_s = (1 - alpha) * o_s + alpha * n_s\n",
    "    \n",
    "    blended_rgb = np.array(hls_to_rgb(blended_h, blended_l, blended_s))\n",
    "    return tuple(blended_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6e7ddf-15e0-43e9-8294-fdb9c952eb09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def display_plots_of_dataset(separate_dfs, patient_intro_days, alpha = .3):\n",
    "    \"\"\"This function plots the raw data for inspection.\n",
    "    Each patient corresponds to a series of rectangles, with face color corresponding to treatment.\n",
    "    The facecolor changes brightness based on the number of days of a consecutive treatment are applied,\n",
    "    setting up potential for conditional dependency analysis between treatment history distributions later\n",
    "    on. It uses a colorsys mapping between a given starting set of RGB tuples, one for each type of \n",
    "    treatment.\"\"\"\n",
    " \n",
    "    x_dim  = 200\n",
    "    y_dim = 200\n",
    "    \n",
    "    data_fig = plt.figure(figsize=(x_dim, y_dim))\n",
    "    matplotlib.rc('xtick', labelsize=14)\n",
    "    matplotlib.rc('ytick', labelsize=14)\n",
    "    \n",
    "    mainPanelHeight = 3.75\n",
    "    mainPanelWidth = 5\n",
    "\n",
    "    otherMainPanelHeight = 3.75\n",
    "    otherMainPanelWidth = 5\n",
    "\n",
    "    legendPanelHeight = 3\n",
    "    legendPanelWidth = .5\n",
    "    \n",
    "    sidePanelHeight = 3\n",
    "    sidePanelWidth = .25\n",
    "    \n",
    "    \n",
    "    #setting up the panels and placing the proper positions\n",
    "    firstMainPanel = plt.axes([.05/x_dim,.375/y_dim, mainPanelWidth/x_dim, mainPanelHeight/\n",
    "    y_dim])\n",
    "    firstMainPanel.set_xlabel(\"Treatment Day\")\n",
    "    firstMainPanel.set_ylabel(\"Patient ID\")\n",
    "    firstMainPanel.set_title(\"Dataset Overview\")\n",
    "\n",
    "    otherMainPanel = plt.axes([.05/x_dim,(1.25+mainPanelHeight)/y_dim, otherMainPanelWidth/x_dim, otherMainPanelHeight/\n",
    "    y_dim])\n",
    "    otherMainPanel.set_xlabel(\"Treatment Day\")\n",
    "    otherMainPanel.set_ylabel(\"Patient ID\")\n",
    "    otherMainPanel.set_title(\"Dataset Overview (Blended)\")\n",
    "\n",
    "    main_bottom = 0.375 / y_dim\n",
    "    main_height = mainPanelHeight / y_dim\n",
    "    main_top = main_bottom + main_height\n",
    "\n",
    "    other_bottom = (1.25 + mainPanelHeight) / y_dim\n",
    "\n",
    "    legend_bottom = (main_top + other_bottom) / 2\n",
    "\n",
    "    #setting up the legend panel\n",
    "    legendRight = plt.axes([(1.5+otherMainPanelWidth)/x_dim,legend_bottom-(.5*legendPanelHeight)/y_dim, legendPanelWidth/x_dim, legendPanelHeight/y_dim])\n",
    "    #seting ticks of legend\n",
    "    legendRight.set_title(\"Treatments (Base Color)\")\n",
    "    legendRight.tick_params(bottom=False, labelbottom=False, left=True, labelleft=True, right=False, labelright=False, top=False, labeltop=False)\n",
    "    \n",
    "    \n",
    "\n",
    "    all_patient_IDS = set()\n",
    "    \n",
    "    starting_colors_dict = defaultdict(tuple)\n",
    "    #getting the set of all treatments\n",
    "    all_treatments_all_patients = set() #mental note: trying to make the mapping work for default colors for each treatment with default dict\n",
    "    for separated_dataframe in separate_dfs: \n",
    "        patient_ID  = set(separated_dataframe[\"patient_id\"].tolist())\n",
    "        \n",
    "        all_patient_IDS.update(patient_ID)\n",
    "        treatments_series_set = set(separated_dataframe[\"treatment\"].tolist())\n",
    "        all_treatments_all_patients.update(treatments_series_set)\n",
    "    #finding the set of n RGB tuples on a linear scale given all of the n treatments that were collected\n",
    "    initial_colors = linear_generator_starting_colors(len(all_treatments_all_patients))\n",
    "\n",
    "\n",
    "\n",
    "    for treatment_type, each_unlightened_color in zip(all_treatments_all_patients, initial_colors):\n",
    "        starting_colors_dict[treatment_type] = each_unlightened_color\n",
    "    \n",
    "    for index, separated_dataframe in enumerate(separate_dfs):\n",
    "        treatment_series_list = separated_dataframe[\"treatment\"].tolist()\n",
    "        current_treatment = treatment_series_list[0]\n",
    "        treatment_streak_length = 1\n",
    "        last_facecolor = starting_colors_dict[treatment_series_list[0]]\n",
    "        for day, which_treatment in enumerate(treatment_series_list):\n",
    "            bar_width = 1\n",
    "            lightness_factor = max(0.7, 1 - 0.05 * (treatment_streak_length - 1)) #used to darken base facecolors for a given treatment with repeated treatment\n",
    "            if which_treatment == current_treatment:\n",
    "                treatment_streak_length+=1 \n",
    "            else:\n",
    "                current_treatment = which_treatment\n",
    "                treatment_streak_length = 1\n",
    "            \n",
    "            #unblended rectangle's facecolor and plotting\n",
    "            unblended_facecolor = starting_colors_dict[which_treatment]\n",
    "            rect_to_add = rect((day, index), width=1, height=1, facecolor=unblended_facecolor, edgecolor='black', linewidth=0.25)\n",
    "            firstMainPanel.add_patch(rect_to_add)\n",
    "\n",
    "            #blended rectangle's facecolor and plotting\n",
    "            r, g, b = unblended_facecolor[0], unblended_facecolor[1], unblended_facecolor[2]\n",
    "            facecolor_unblended_hls  = rgb_to_hls(r, g, b)\n",
    "            streak_aware_facecolor_unblended = hls_to_rgb(facecolor_unblended_hls[0], facecolor_unblended_hls[1]*lightness_factor, facecolor_unblended_hls[2])\n",
    "            blended_streak_aware_facecolor = blend_old_and_new_color(last_facecolor, streak_aware_facecolor_unblended, alpha)\n",
    "            \n",
    "\n",
    "            blended_rect_to_add = rect((day, index), width=1, height=1, facecolor=blended_streak_aware_facecolor, edgecolor='black', linewidth=0.25)\n",
    "            otherMainPanel.add_patch(blended_rect_to_add)\n",
    "            last_facecolor = blended_streak_aware_facecolor\n",
    "\n",
    "    \n",
    "    # setting limits of first panel and second panel\n",
    "    max_days = max(len(df[\"treatment\"]) for df in separate_dfs)\n",
    "    firstMainPanel.set_xlim(0, max_days)\n",
    "    firstMainPanel.set_ylim(0, len(separate_dfs) - 0.5)\n",
    "    firstMainPanel.set_yticks([index for index in range(len(separate_dfs))])\n",
    "    firstMainPanel.set_yticklabels(all_patient_IDS)\n",
    "    firstMainPanel.invert_yaxis()  \n",
    "\n",
    "    otherMainPanel.set_xlim(0, max_days)\n",
    "    otherMainPanel.set_ylim(0, len(separate_dfs) - 0.5)\n",
    "    otherMainPanel.set_yticks([index for index in range(len(separate_dfs))])\n",
    "    otherMainPanel.set_yticklabels(all_patient_IDS)\n",
    "    otherMainPanel.invert_yaxis()\n",
    "\n",
    "    #adding base colors to the legend panel\n",
    "    legendRight.set_xlim(0,.1)\n",
    "    legendRight.set_ylim(0,len(all_treatments_all_patients))\n",
    "    \n",
    "    which_y = 0\n",
    "    for treatment, starting_color in starting_colors_dict.items():\n",
    "        given_rectangle = rect((0, which_y), width = 1, height = 1, facecolor = starting_color, edgecolor='black', linewidth=0.25)\n",
    "        legendRight.add_patch(given_rectangle)\n",
    "        which_y+=1\n",
    "    legendRight.set_yticks([index+.5 for index in range(len(starting_colors_dict.keys()))])\n",
    "    legendRight.tick_params(axis='y', labelsize=10)\n",
    "    legendRight.set_yticklabels(starting_colors_dict.keys())\n",
    "    \n",
    "    \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02eddf59-990d-4fde-a9d7-b9b05272e594",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_history_metadata(seperatePatientsDFs, allPatientsIntroDays):\n",
    "\n",
    "    \"\"\"Function that adds a treatment history metadata column to each patient's dataframe by...\n",
    "    1) Loading each seperate patient's dataframe and compute the average baseline severity, normalizing acne severity scores. Then modifies the dataframe, called a severities dataframe.\n",
    "    2) For each, mapping each value for treatment to the a treatment history tuple. It is a tuple of the form ((days of treatment, ai), (days of treatment, ai+1),....(days of treatment, an))\n",
    "    where n is the row number of the current day of the particular treatment.\"\"\"\n",
    "    \n",
    "    \n",
    "    #initializing dict containing severties by day for a given treatment \n",
    "    severitiesDayTreatmentDict = {treatment: None for treatment in seperatePatientsDFs[0][\"treatment\"]}\n",
    "    \n",
    "    modifiedDFs = []\n",
    "    counter = 0 \n",
    "\n",
    "    for patient_DF, days_of_intro in zip(seperatePatientsDFs, allPatientsIntroDays):\n",
    "        #computing average baseline severity for each DF\n",
    "        average_bl = patient_DF[\"AcneSeverity\"].head(days_of_intro[0][2]).mean()\n",
    "        \n",
    "        #forming new dataframe from old one containing percent severity over baseline \n",
    "        modified_DF = patient_DF.copy()\n",
    "        \n",
    "        \n",
    "        modified_DF[\"AcneSeverity\"] = modified_DF[\"AcneSeverity\"].apply(lambda x: (x - average_bl)/average_bl)*100\n",
    "        modifiedDFs.append(modified_DF)\n",
    "        counter += 1\n",
    "    \n",
    "    metadata_DFs = []\n",
    "    all_patients_treatment_histories = []\n",
    "    #iterating over all dataframes and their respective treatment days of introduction\n",
    "    for severities_df, days_of_intro in zip (modifiedDFs, allPatientsIntroDays): \n",
    "        #for each dataframe and the corresponding set of days where a given treatment ends\n",
    "        \n",
    "        #adding an explicit day column to each severities dataframe to enable indexing with df.loc  \n",
    "        severities_df[\"day\"] = range(len(severities_df))\n",
    "    \n",
    "        #initializing the treatment history metadata column\n",
    "        severities_df[\"treatment_history\"] = None\n",
    "    \n",
    "        last_treat_index = 0 #keeps track of which number of the ordered list of treatments is currently being processed\n",
    "        treatment_days = {} #keeping track of how many days each particular treatment goes on for\n",
    "        treatment_history = [] #keeping track of the full history of which treatment occurs before the others and how long they last for\n",
    "        all_treatment_histories = []\n",
    "        #also keeping track of the last treatment\n",
    "        last_treatment_itself = None\n",
    "        \n",
    "        #iterating through rows of the dataframe\n",
    "        \n",
    "        for row_index, row in severities_df.iterrows():\n",
    "            current_day = row[\"day\"]\n",
    "            current_treatment = row[\"treatment\"]\n",
    "                   \n",
    "            #also checking to see if the current treatment is entirely new or falls inside a different treatment block\n",
    "            if current_treatment != last_treatment_itself:\n",
    "                treatment_days[current_treatment] = 1  # First day of new treatment\n",
    "                treatment_history.append((current_treatment, 1))\n",
    "            else:\n",
    "                treatment_days[current_treatment] += 1\n",
    "                treatment_history[-1] = (current_treatment, treatment_days[current_treatment])\n",
    "            \n",
    "            \n",
    "            #once history is built, the history is stored in the original dataframe as an entry in own column\n",
    "            severities_df.at[row_index, \"treatment_history\"] = list(treatment_history)\n",
    "        \n",
    "            transient_history = treatment_history.copy()\n",
    "            all_treatment_histories.append(transient_history)\n",
    "    \n",
    "            last_treatment_itself = current_treatment  \n",
    "            \n",
    "        #also modifying dataframes to remove baseline acne severities, as they've already been used\n",
    "        metadata_DFs.append(severities_df[days_of_intro[0][2]:])\n",
    "        \n",
    "        all_patients_treatment_histories.append(all_treatment_histories)\n",
    "    return metadata_DFs, all_patients_treatment_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b90fe3-6485-49aa-aa16-85435ae09c65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_confidence_intervals(metadata_DFs, quantiles):\n",
    "    \"\"\"Checking the confidence intervals of the quantiles to ensure they don't overlap.\"\"\"\n",
    "    #collecting all severities, converting all to positive values, flattening as we go\n",
    "    all_severities = []\n",
    "    for df in metadata_DFs:\n",
    "        all_severities.extend(df[\"AcneSeverity\"] * -1)\n",
    "    boostrapped_CIs = bootstrap_CI_margin_of_error(all_severities, quantiles)\n",
    "    return boostrapped_CIs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b12034",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_and_plot_severity_states(metadata_DFs):\n",
    "    \"\"\"Determines the quantile cutoff determining the quantiles corresponding to categorical acne severity states (low, medium, and high), by\n",
    "    1) Computing the KDE of the distribution of all normalized acne severity scores over all patients and treatment histories.\n",
    "    2) Using optimization to find the saddle point of the distribution and consolidating with the modes.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, figsize = (5, 5))\n",
    "    \n",
    "    \n",
    "    #collecting all severities, converting all to positive values, flattening as we go\n",
    "    all_severities = []\n",
    "    for df in metadata_DFs:\n",
    "        all_severities.extend(df[\"AcneSeverity\"] * -1)\n",
    "    \n",
    "    #check for normal character by plotting histogram\n",
    "    severities_histo = np.histogram(all_severities, density = True)\n",
    "    #axes.hist(all_severities, bins  = 30, density = True)\n",
    "    axes.set_title(\"Acne Severities Distribution (relative to baseline)\") \n",
    "    axes.set_xlabel(\"Normalized Severity Score\")\n",
    "    axes.set_ylabel(\"Density\")\n",
    "    \n",
    "    \n",
    "    #fitting a kernel density estimate to the data\n",
    "    \n",
    "    sns.kdeplot(all_severities, fill=True)\n",
    "    plt.title(\"KDE of Acne Severity Distribution\")\n",
    "    \n",
    "    #extracting the equation of the pdf and finding the local minimum in between the two modes\n",
    "    kde_pdf = sp.stats.gaussian_kde(all_severities)\n",
    "    \n",
    "    #using max and min of pdf to find saddle point in between 2 modes, sampling 1000 points\n",
    "    severity_grid = np.linspace(np.min(all_severities), np.max(all_severities), 1000)\n",
    "    \n",
    "    neg_kde = lambda x: -kde_pdf(x.reshape(1, -1))\n",
    "    \n",
    "    #finding the two main modes using optimization, with first 2 mode guesses at the .2 and .8 quantiles\n",
    "    guesses = np.percentile(all_severities, [20, 80]) \n",
    "    \n",
    "    modes = []\n",
    "    for guess in guesses:\n",
    "        better = optimize.minimize(neg_kde, np.array([guess])) \n",
    "        modes.append(better.x[0]) \n",
    "    \n",
    "    modes = np.array(modes)\n",
    "    \n",
    "    #finding the saddle point in between the two modes, using that as cutoff for the two patient states\n",
    "    \n",
    "    initial_guess = np.mean(modes) #average of the modes\n",
    "    bds = [(min(modes)+1, max(modes)-1)]  # This is a list of two tuples for each mode\n",
    "    \n",
    "    saddle_pt = optimize.minimize(kde_pdf, [initial_guess], bounds = bds) \n",
    "    state_ranges = [modes[0], saddle_pt.x[0], modes[1]]\n",
    "    state_names = [\"High Severity\", \"Medium Severity\", \"Low Severity\"]\n",
    "    \n",
    "    \n",
    "    #plotting modes and saddle point over the distribution\n",
    "    plt.scatter(modes[0], kde_pdf(modes[0]), color = \"red\", label = \"Lower Mode\")\n",
    "    plt.scatter(modes[1], kde_pdf(modes[1]), color = \"red\", label = \"Upper Mode\")\n",
    "    plt.scatter([saddle_pt.x[0]], kde_pdf([saddle_pt.x[0]]), color='green', label=\"Saddle Point\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return state_names, state_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4b582f-752c-46f0-8ce4-8c4192da188b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def assign_states_to_mdfs(metadata_DFs, state_names, orig_state_ranges):\n",
    "    \"\"\"Function to construct and attach a second metadata column onto each patient's dataframe. The column contains\n",
    "    the acne severity categorical state corresponding to a given treatment history.\"\"\"\n",
    "    \n",
    "    new_ranges = [float(orig_state_ranges[0]), float(orig_state_ranges[1]), float(orig_state_ranges[2])]\n",
    "\n",
    "    \n",
    "    for patient_df in metadata_DFs:\n",
    "        severity_states = np.digitize(-1 * patient_df[\"AcneSeverity\"], new_ranges, right = False)\n",
    "        severity_states = np.minimum(severity_states, 2)\n",
    "        patient_df[\"State\"] = [state_names[severity_state] for severity_state in severity_states] \n",
    "\n",
    "    return metadata_DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa4b1c5-9097-4e44-b2da-67cbdb2827b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def validate_state_assignments_with_bootstrapping_result(metadata_DFs, state_names, orig_state_ranges, boot_middle_qs_dict):\n",
    "    \"\"\"Function that validates if state assignments are valid in the context of hard binning (in particular around\n",
    "    the saddle point).\"\"\"\n",
    "    # Helper: extract the original labels once\n",
    "    # Original state assignments\n",
    "    orig_mdfs = copy.deepcopy(metadata_DFs)\n",
    "    orig_mdfs = assign_states_to_mdfs(orig_mdfs, state_names, orig_state_ranges)\n",
    "    orig_labels = np.concatenate([df[\"State\"].values for df in orig_mdfs])\n",
    "\n",
    "    fracs_changed = {}\n",
    "\n",
    "    # Iterate over numeric middle cutpoints (q̂) in the bootstrap dict\n",
    "    for qhat, boot_info in boot_middle_qs_dict.items():\n",
    "        frac_changed = []\n",
    "\n",
    "        # Iterate over bootstrap samples of the middle cutpoint\n",
    "        for q in boot_info['bootstrap_samples']:\n",
    "            # Ensure numeric\n",
    "            q = float(q)\n",
    "\n",
    "            # Update the middle cutpoint only\n",
    "            low, high = float(orig_state_ranges[0]), float(orig_state_ranges[2])\n",
    "            middle = float(q)\n",
    "            epsilon = 1e-6\n",
    "            middle = max(low + epsilon, min(middle, high - epsilon))\n",
    "            new_ranges = [low, middle, high]\n",
    "\n",
    "            # Reassign states with the adjusted middle cut\n",
    "            mdfs_try = copy.deepcopy(metadata_DFs)\n",
    "            mdfs_try = assign_states_to_mdfs(mdfs_try, state_names, new_ranges)\n",
    "            new_labels = np.concatenate([df[\"State\"].values for df in mdfs_try])\n",
    "\n",
    "            # Fraction of labels that changed\n",
    "            diff_frac = np.mean(new_labels != orig_labels)\n",
    "            frac_changed.append(diff_frac)\n",
    "\n",
    "        frac_changed = np.array(frac_changed)\n",
    "\n",
    "        print(f\"For middle cutpoint q̂={qhat:.4f}\")\n",
    "        print(f\"Median fraction changed: {np.median(frac_changed):.3f}\")\n",
    "        print(f\"5th–95th percentile range: ({np.percentile(frac_changed,5):.3f}, {np.percentile(frac_changed,95):.3f})\\n\")\n",
    "\n",
    "        fracs_changed[qhat] = frac_changed\n",
    "\n",
    "    return fracs_changed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f70894-26f3-4bbc-9f7c-8965c525ac9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_histograms(metadata_DFs):\n",
    "    \"\"\"This algorithm iterates over all patients' severity dataframes and, for each... \n",
    "\n",
    "    1) Counts all of the occcurences of each acne severity state throughout all patients, and assigns those counts \n",
    "    as a value to the treatment history key in the state counts dictionary.\n",
    "    2) Normalizes the counts into distributions before returning both. \n",
    "    \"\"\"\n",
    "    \n",
    "    all_state_counts = defaultdict(Counter)\n",
    "  \n",
    "    for i, patient_df in enumerate(metadata_DFs):\n",
    "        histories = patient_df[\"treatment_history\"].values\n",
    "        states = patient_df[\"State\"].values\n",
    " \n",
    "        for state_index in range(1, len(states)):\n",
    "            current_state = states[state_index] #state at position state_index in the patient's dataframe\n",
    "            current_history = histories[state_index] #metadata (treatment history) at position state_index  in the patient's dataframe\n",
    "            current_history_key = tuple((str(treatment), int(days)) for treatment, days in current_history)\n",
    "           \n",
    "            #recording the actual counts of severities, with the context of the prior treatment as the key\n",
    "            all_state_counts[current_history_key][current_state] += 1\n",
    "\n",
    "    #normalizing counts dictionaries into distributions\n",
    "    first_order_probabilities = {}\n",
    "    \n",
    "    for previous_treatment, state_counts in all_state_counts.items():\n",
    "        total_counts  = sum(state_counts.values())\n",
    "        probabilities_given_previous_state = {state: count/total_counts for state, count in state_counts.items()}\n",
    "        first_order_probabilities[previous_treatment] = probabilities_given_previous_state\n",
    "\n",
    "    return (all_state_counts, first_order_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f891c9d8-479f-443f-a07d-880fd55b54a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_histograms(first_order_probabilities):\n",
    "    \"\"\" This function plots a striped heatmap to inspect the distributions of normalized acne severity states for each treatment history.\n",
    "    It uses a viridis heatmap implementation from my other repository figuresAndViewers.\n",
    "    In lieu of using the actual treatment histories themselves as x labels, the x label is the index of the history in the sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_dim  = 100\n",
    "    y_dim = 200\n",
    "    \n",
    "    fig = plt.figure(figsize=(x_dim, y_dim))\n",
    "    matplotlib.rc('xtick', labelsize=14)\n",
    "    matplotlib.rc('ytick', labelsize=14)\n",
    "\n",
    "      \n",
    "    #plotting histograms of each context dependent model of acne treatment severity\n",
    "    bar_width = 0.3\n",
    "    spacing = 0.05 \n",
    "    \n",
    "    #sorting the distributions by the state name in reverse \n",
    "    \n",
    "    real_first_order_probabilities = dict(sorted(first_order_probabilities.items(), reverse = True))\n",
    "    #print(\"reals\", real_first_order_probabilities)\n",
    "    \n",
    "    mainPanelHeight = 15\n",
    "    mainPanelWidth = 20\n",
    "\n",
    "    legendPanelHeight = .25\n",
    "    legendPanelWidth = .5\n",
    "    \n",
    "    sidePanelHeight = 3\n",
    "    sidePanelWidth = .25\n",
    "    \n",
    "    \n",
    "    #setting up the panels and placing the proper positions\n",
    "    firstMainPanel = plt.axes([.05/x_dim,.375/y_dim, mainPanelWidth/x_dim, mainPanelHeight/\n",
    "    y_dim])\n",
    "    firstMainPanel.set_xlabel(\"Treatment History Index\")\n",
    "    firstMainPanel.set_title(\"Raw Distributions of Normalized Acne Severity States\")\n",
    "\n",
    "    #setting up the legend panel\n",
    "    legendRight = plt.axes([(1+mainPanelWidth)/x_dim, legendPanelHeight/y_dim, legendPanelWidth/x_dim, mainPanelHeight/y_dim])\n",
    "    #seting ticks of legend\n",
    "    legendRight.tick_params(bottom=False, labelbottom=False, left=True, labelleft=True, right=False, labelright=False, top=False, labeltop=False)\n",
    "    \n",
    "    legendRight.set_xlim(0,.1)\n",
    "    legendRight.set_ylim(0,20)\n",
    "    legendRight.set_yticks([0,20],['0','1'])\n",
    "    \n",
    " \n",
    "    #looping through to construct a heatmap for all distributions\n",
    "    entries = len(real_first_order_probabilities)\n",
    "    bar_width = 1 / entries\n",
    "    firstMainPanel.set_xlim(0, 1)\n",
    "    firstMainPanel.set_ylim(0, 1)\n",
    "\n",
    "    x_pos = 0\n",
    "    for history, raw_distribution in real_first_order_probabilities.items():\n",
    "        distribution = defaultdict(float, raw_distribution)\n",
    "        scaled_x_pos = x_pos * bar_width\n",
    "\n",
    "        high_fc = viridis(distribution[\"High Severity\"])[:3]\n",
    "        med_fc  = viridis(distribution[\"Medium Severity\"])[:3]\n",
    "        low_fc  = viridis(distribution[\"Low Severity\"])[:3]\n",
    "    \n",
    "\n",
    "        firstMainPanel.add_patch(rect([scaled_x_pos, 2/3], width=bar_width, height=1/3, facecolor=high_fc, edgecolor='black', linewidth=0.25))\n",
    "        firstMainPanel.add_patch(rect([scaled_x_pos, 1/3], width=bar_width, height=1/3, facecolor=med_fc, edgecolor='black', linewidth=0.25))\n",
    "        firstMainPanel.add_patch(rect([scaled_x_pos, 0],   width=bar_width, height=1/3, facecolor=low_fc, edgecolor='black', linewidth=0.25))\n",
    "\n",
    "        x_actual_spot = scaled_x_pos + bar_width / 2\n",
    "\n",
    "        x_pos += 1\n",
    "    num_rects = len(real_first_order_probabilities)\n",
    "    tick_positions = [i * bar_width + bar_width / 2 for i in range(num_rects)]\n",
    "\n",
    "    firstMainPanel.set_xticks(tick_positions)\n",
    "    firstMainPanel.set_xticklabels(['' for _ in tick_positions])\n",
    "    #firstMainPanel.set_yticks([1/6, 0.5, 5/6], [\"Low Severity\", \"Medium Severity\", \"High Severity\"], fontsize = 15)\n",
    "    firstMainPanel.set_yticks([1/6, 0.5, 5/6])\n",
    "    firstMainPanel.set_yticklabels([\"Low Severity\", \"Medium Severity\", \"High Severity\"], fontsize=15)\n",
    "        \n",
    "    #plotting viridis heatmap in the sidebar\n",
    "    #color map tuple pair linspaces, viridis values\n",
    "    vvLin1Red = np.linspace(68/255, 59/255, 5)\n",
    "    vvLin2Red = np.linspace(59/255, 33/255, 6)\n",
    "    vvLin3Red = np.linspace(33/255, 94/255, 6)\n",
    "    vvLin4Red = np.linspace(94/255, 253/255, 6)\n",
    "    \n",
    "    \n",
    "    vvLin1Green = np.linspace(1/255, 82/255, 5)\n",
    "    vvLin2Green = np.linspace(82/255, 145/255, 6)\n",
    "    vvLin3Green = np.linspace(145/255, 201/255, 6)\n",
    "    vvLin4Green = np.linspace(201/255, 231/255, 6)\n",
    "    \n",
    "    vvLin1Blue = np.linspace(84/255, 139/255, 5)\n",
    "    vvLin2Blue = np.linspace(139/255, 140/255, 6)\n",
    "    vvLin3Blue = np.linspace(140/255, 98/255, 6)\n",
    "    vvLin4Blue = np.linspace(98/255, 37/255, 6)\n",
    "    \n",
    "    \n",
    "    plLin4Red = np.linspace(245/255, 237/255, 5)\n",
    "    plLin3Red = np.linspace(190/255, 245/255, 6)\n",
    "    plLin2Red = np.linspace(87/255, 190/255, 6)\n",
    "    plLin1Red = np.linspace(15/255, 87/255, 6)\n",
    "    \n",
    "    plLin4Green = np.linspace(135/255,252/255, 5)\n",
    "    plLin3Green = np.linspace(48/255, 135/255, 6)\n",
    "    plLin2Green = np.linspace(0/255, 48/255, 6) \n",
    "    plLin1Green = np.linspace(0/255, 0/255, 6)\n",
    "    \n",
    "    plLin4Blue = np.linspace(48/255, 27/255, 5)\n",
    "    plLin3Blue = np.linspace(101/255, 48/255,  6)\n",
    "    plLin2Blue = np.linspace(151/255, 101/255, 6)\n",
    "    plLin1Blue = np.linspace(118/255, 151/255, 6)\n",
    "    \n",
    "    \n",
    "    #total linspaces for all tuple pairs, viridis values\n",
    "    vvListOfRedLins = list(vvLin1Red)+list(vvLin2Red)+list(vvLin3Red)+list(vvLin4Red)\n",
    "    vvListOfGreenLins = list(vvLin1Green)+list(vvLin2Green)+list(vvLin3Green)+list(vvLin4Green)\n",
    "    vvListOfBlueLins = list(vvLin1Blue)+list(vvLin2Blue)+list(vvLin3Blue)+list(vvLin4Blue)\n",
    "    \n",
    "    orderedVVRed = list(dict.fromkeys(vvListOfRedLins))\n",
    "    orderedVVGreen = list(dict.fromkeys(vvListOfGreenLins))\n",
    "    orderedVVBlue = list(dict.fromkeys(vvListOfBlueLins))\n",
    "    \n",
    "    \n",
    "    #viridis heatmaps into the legend panel\n",
    "    for index in range(0,20,1):\n",
    "    \tcolorPaletteVV = (orderedVVRed[index], orderedVVGreen[index], orderedVVBlue[index])\n",
    "    \tvvGradeRect = rect([0,index], .1, 8, facecolor=colorPaletteVV,edgecolor = 'black', linewidth = 0)\t\t\n",
    "    \tlegendRight.add_patch(vvGradeRect)\n",
    "\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.savefig(\"Raw_Striped_Heatmap\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b593e9c-8970-4d5b-8e59-e08154a0d7fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_CI_margin_of_error(actual_values, observed_quantile_values, B=5000, bandwidth=0.05):\n",
    "    \"\"\"Short function to approximate the margin of error (MOE) for the bimodal KDE presented here. Uses Bootstrapping to approximate \n",
    "    the 95% confidence interval for each quantile, and halves each of them to give MOE.\"\"\"\n",
    "\n",
    "    data = np.asarray(actual_values)\n",
    "    n = len(data)\n",
    "    kde = KernelDensity(bandwidth=bandwidth).fit(data[:, None])\n",
    "    rng = np.random.default_rng(123)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for qhat in observed_quantile_values:\n",
    "        boot_q = np.empty(B)\n",
    "        # compute percentile of qhat in original data\n",
    "        p = (data < qhat).mean()\n",
    "        for b in range(B):\n",
    "            smpl = kde.sample(n_samples=n, random_state=123 + b).ravel()\n",
    "            boot_q[b] = np.quantile(smpl, p)  # same percentile in resampled data\n",
    "\n",
    "        ci_lower, ci_upper = np.percentile(boot_q, [2.5, 97.5])\n",
    "        moe = 0.5 * (ci_upper - ci_lower)\n",
    "\n",
    "        results[qhat] = {\n",
    "            'CI': (ci_lower, ci_upper),\n",
    "            'MOE': moe,\n",
    "            'bootstrap_samples': boot_q\n",
    "        }\n",
    "\n",
    "        # plot histogram\n",
    "        plt.figure()\n",
    "        plt.hist(boot_q, bins=80)\n",
    "        plt.axvline(qhat, color='k', linestyle='--', label='observed cutpoint')\n",
    "        plt.title(f'Smoothed bootstrap distribution for cutpoint {qhat:.2f}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Cutpoint={qhat:.4f}, 95% CI=({ci_lower:.4f},{ci_upper:.4f}), MOE={moe:.4f}\")\n",
    "\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b0c4a7-7d72-4a01-9289-bec85b3aee6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_Dirichlet(prior, all_transition_counts):\n",
    "    \"\"\"This function does the following: \n",
    "    Accepts a prior in order to construct a Bayesian model of each history's distribution as a Dirichlet distribution with a multinomial \n",
    "    likelihood. It does so by the following methods. \n",
    "    1)  Iterates through each set of counts for each history and adds them to each parameter in order in the prior, then uses these to\n",
    "    build the posterior Dirichlet distribution.\"\"\"\n",
    "\n",
    "    categories = ['Low Severity', 'Medium Severity', 'High Severity']\n",
    "    prior_dict = {'Low Severity': prior[0], \"Medium Severity\": prior[1], \"High Severity\": prior[2]}\n",
    "    \n",
    "    history_and_posteriors = {}\n",
    "\n",
    "    \n",
    "    for history, count_dict in all_transition_counts.items():\n",
    "        \n",
    "        counts = [count_dict.get(cat, 0) for cat in categories] #pulling counts from prior dict and counts dict\n",
    "        prior = [prior_dict[cat] for cat in categories] \n",
    "\n",
    "        #updating parameters for posterior distribution\n",
    "        posterior_params = np.array(counts) + np.array(prior)\n",
    "            \n",
    "        \n",
    "        #saving posterior params to the dictionary\n",
    "        history_and_posteriors[history] = posterior_params\n",
    "        \n",
    "    return history_and_posteriors, categories   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46c178be-9f94-45ab-b455-6011f2002cff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_dirichlet_marginal_cis(alphas, confidence_level = .95):\n",
    "    \"\"\"Function that is wrapped by the below function. Calculates the upper and lower quantiles supplied by confidence interval\n",
    "    for each marginal beta distribution of a given dirichlet. Returns each confidence interval indexed by the respective alpha.\"\"\"\n",
    "    confidence_intervals = {}\n",
    "    top_density = (1 - confidence_level)/2\n",
    "    bottom_density = 1 - top_density\n",
    "    total_alpha = np.sum(alphas)\n",
    "    \n",
    "\n",
    "    for index, alpha in enumerate(alphas):\n",
    "        other_alpha_sum = total_alpha - alpha\n",
    "        lower_bound = beta.ppf(bottom_density, alpha, other_alpha_sum)\n",
    "        upper_bound = beta.ppf(top_density, alpha, other_alpha_sum)\n",
    "        confidence_intervals[index] = (lower_bound, upper_bound)\n",
    "\n",
    "    return confidence_intervals\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d6430c-3d34-4643-8e74-0e45a68924cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_Dirichlets_credible_interals(histories_and_dirichlets, ordered_categories, confidence_level = .95):\n",
    "    \"\"\"This function finds the 95% credible intervals for each component of the Dirichlet distribution for all treatment histories.\n",
    "    It ensures that a stacked plot is made.\"\"\"\n",
    "    \n",
    "    #checking to see if no categories are supplied; just uses indices of each state to name categories in that case\n",
    "    if ordered_categories is None:\n",
    "        ordered_categories = [f\"State {i}\" for i in range(len(dirichlet_posteriors[0]))]\n",
    "    \n",
    "    fig, ax = plt.subplots(len(ordered_categories), 1, figsize=(len(ordered_categories) * 3.5, 7), sharex = True)\n",
    "    ax[-1].set_xlabel(\"History Index\")\n",
    "    ax[len(ax)-1].set_title(\"95% Credible Intervals for marginal acne severity state distributions\")\n",
    "    #ax.set_title(\"95% Credible Intervals for marginal acne severity state distributions\")\n",
    "    jitter_spacing = .5\n",
    "    left_end = 0 \n",
    "    for history, alphas in histories_and_dirichlets.items():\n",
    "        \n",
    "        these_confidence_intervals = find_dirichlet_marginal_cis(alphas)\n",
    "        for subplot_index, ordered_confidence_interval in these_confidence_intervals.items():\n",
    "            #ax[subplot_index].set_xticks(np.arange(len(histories_and_dirichlets)))\n",
    "            #ax[subplot_index].set_xticklabels(list(histories_and_dirichlets.keys()))\n",
    "            x = left_end + (subplot_index - len(these_confidence_intervals)/2) * jitter_spacing  # adding some x offset for the error bars\n",
    "            center = (ordered_confidence_interval[1] + ordered_confidence_interval[0])/2\n",
    "            width = ordered_confidence_interval[0] - ordered_confidence_interval[1]\n",
    "            \n",
    "            ax[len(ordered_categories) - subplot_index - 1].errorbar(x, center, yerr = width/2, fmt='o', color='C0', capsize=5)\n",
    "            \n",
    "        left_end += 1\n",
    "            \n",
    "    for i, name in enumerate(reversed(ordered_categories)):\n",
    "        ax[i].set_ylabel(name)\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30a3960-860a-4936-9901-51857787cc69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_KL_Divergence_vectorized(histories_and_posteriors):\n",
    "    \"\"\"This vectorized function calculates the Kullback-Leibler divergence between adjacent \n",
    "    3 dimensional Dirichlet distributions, each of which is indexed by its alpha parameter.\n",
    "    It does this for a full array, computing KL Divergence for each term alpha[i] and alpha[i+1]. So, it requires \n",
    "    you to supply two arrays of parameters, but really, just the same one read forwards and backwards.\n",
    "    \"\"\"\n",
    "    history_labels = list(histories_and_posteriors.keys())\n",
    "    x_vals = np.arange(1, len(history_labels))\n",
    "\n",
    "    alphas = np.array(list(histories_and_posteriors.values()))\n",
    "    alphas_backward = alphas[:-1]\n",
    "    alphas_forward = alphas[1:]\n",
    "\n",
    "    #ensuring alphas are non-0 up front\n",
    "    sum_forward = np.sum(alphas_forward, axis=1)\n",
    "    sum_backward = np.sum(alphas_backward, axis=1)\n",
    "\n",
    "    first_term = gammaln(sum_forward) - gammaln(sum_backward)\n",
    "    second_term = np.sum(gammaln(alphas_backward) - gammaln(alphas_forward), axis=1)\n",
    "    third_term = np.sum(\n",
    "        (alphas_forward - alphas_backward) * \n",
    "        (psi(alphas_forward) - psi(sum_forward)[:, None]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    kl_div = first_term + second_term + third_term\n",
    "    cumulative_kl = np.cumsum(kl_div)\n",
    "    cumulative_kl = np.clip(cumulative_kl, 1e-10, None)  # Avoid log(0)\n",
    "\n",
    "    return x_vals, np.log(cumulative_kl), cumulative_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "847a51f9-b0c2-4b11-a5fd-0636d9e308ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(points, predictions):\n",
    "    \"\"\"This function is wrapped by fit_piecewise_regression. It uses maximum-likelihood estimation\n",
    "    to estimate the MLE of variance in the residuals for a linear regression model. \n",
    "    It then uses the sample size of the points from the model to find the log likelihood of \n",
    "    the actual points given the model fit to it.\"\"\"\n",
    "\n",
    "    residuals = np.array(points - predictions)\n",
    "    mle_variance_residuals = (1/len(points)) * np.sum((residuals ** 2))\n",
    "    log_likelihood = (-len(points)/2) * (np.log10(2*np.pi) + np.log(mle_variance_residuals) + 1) \n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c898ff44-216c-4099-88c4-f399172077bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def split_for_piecewise_regression(xs, cumulative_kls, percentile_cutoff = 80, split_index = None, gaussian_sigma = 1, slope_threshold = 0.2,\n",
    "                            min_segment_length = 3):\n",
    "    \"\"\"This algorithm uses a brute force method to find the inflection points to fit piecewise regression models to the data.\n",
    "    But first...\n",
    "    It dynamically chooses the right number of inflection points to fit each model to via the following...\n",
    "    1) It smoothes the cumulative KL divergence array with a Gaussian filter (by default is standard normal). \n",
    "    2) It computes pairwise slopes between adjacent cumulative KL values (with each x interval = 1/number of steps in treatment history)\n",
    "    ^check that later\n",
    "    3) Computes differences between adjacent slopes, returning a 2nd derivative approximation for the entire array\n",
    "    4) (Currently commented out) Plots the distribution of the magnitudes for inspection.\n",
    "    5) A cutoff for inflection points is chosen as a percentile of the 2nd derivative magntitdes (default is 90th). \n",
    "\n",
    "    Then, it iterates through the found inflection points, dividing them into subarrays of consecutive points. Once it does this, it does \n",
    "    one final check to see if each subarray should be further divided. It does this by iterating through each array, comparing the difference in \n",
    "    adjacent slopes pairwise, checking their difference against the provided slope threshold parameter. It then makes a list of lists of \n",
    "    inflection points where the regression models should start and end.\n",
    "\n",
    "    It then uses the result of this to further divide the points into subarrays that a regression model can be fit to.\n",
    "    At last, it checks the length of each subarray against the minimum segment length, and discards ones that are too small.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    smoothed_kls = gaussian_filter1d(cumulative_kls, sigma = gaussian_sigma)\n",
    "    slopes = np.diff(smoothed_kls)\n",
    "    second_derivatives_magnitudes = np.abs(np.diff(slopes))\n",
    "    threshold = np.percentile(second_derivatives_magnitudes, percentile_cutoff)\n",
    "    inflection_points = np.where(second_derivatives_magnitudes > threshold)[0] + 1\n",
    "\n",
    "    differences = np.diff(inflection_points)\n",
    "    non_consecutive_indices = np.where(differences != 1)[0] + 1 \n",
    "    separated_inflection_points = np.array_split(inflection_points, non_consecutive_indices)\n",
    "\n",
    "    \n",
    "    #adding the end of the array to the non_consecutive indices for easier splitting later\n",
    "    #separated_inflection_points[-1] = np.append(separated_inflection_points[len(separated_inflection_points)-1], len(smoothed_kls)-1)    \n",
    "    #^above is causing issues\n",
    "    all_breaks = []\n",
    "\n",
    "    \n",
    "\n",
    "    #print(\"here they are\", separated_inflection_points)\n",
    "    for consecutives_array in separated_inflection_points:\n",
    "        index_consecutives_array = 0\n",
    "        last_inflection_pt = 0 \n",
    "        last_slope = 0\n",
    "\n",
    "        consecutives_breaks = []\n",
    "        \n",
    "        for an_inflection_pt in consecutives_array:\n",
    "            if an_inflection_pt >= len(slopes):\n",
    "                continue\n",
    "            slope_current = slopes[an_inflection_pt]\n",
    "\n",
    "            slope_difference = np.abs(slope_current - last_slope)\n",
    "            \n",
    "            \n",
    "            if slope_difference > slope_threshold:\n",
    "                consecutives_breaks.append(an_inflection_pt)\n",
    "            \n",
    "            last_slope = slope_current\n",
    "            last_inflection_pt = an_inflection_pt\n",
    "\n",
    "        all_breaks.append((consecutives_breaks, index_consecutives_array))\n",
    "\n",
    "        index_consecutives_array += 1 \n",
    "   \n",
    "\n",
    "    fixed_consecutives = []\n",
    "    for breaks, index in all_breaks:\n",
    "        \n",
    "        \n",
    "        if len(breaks) != 0:\n",
    "            consecutives_array_to_split = separated_inflection_points[index]\n",
    "            last_breaking_index = breaks[0] - 1\n",
    "            for breaking_index in breaks:\n",
    "                \n",
    "                broken_consecutives_array = consecutives_array_to_split[last_breaking_index: breaking_index+1]\n",
    "                fixed_consecutives.append(broken_consecutives_array)\n",
    "                last_breaking_index = breaking_index\n",
    "    \n",
    "    #clipping the appropriate array in the inflection point array of arrays \n",
    "    clipped_inflection_points = []\n",
    "    last_consecutive_break = None\n",
    "\n",
    "    # Find the last break if it exists\n",
    "    if fixed_consecutives:\n",
    "        last_consecutive_break = fixed_consecutives[-1][-1]\n",
    "\n",
    "    # Search for that break in the separated inflection points\n",
    "    where_clipping = None\n",
    "    for i, again_consecutives_array in enumerate(separated_inflection_points):\n",
    "        if last_consecutive_break in again_consecutives_array:\n",
    "            idx = np.where(again_consecutives_array == last_consecutive_break)[0][0]\n",
    "            clipped_inflection_points.append(again_consecutives_array[idx + 1:])\n",
    "            where_clipping = i\n",
    "            break  # stop after finding the first match\n",
    "\n",
    "    # Combine final splits\n",
    "    if where_clipping is not None:\n",
    "        full_splits = fixed_consecutives + clipped_inflection_points + separated_inflection_points[where_clipping+1:]\n",
    "    else:\n",
    "        full_splits = fixed_consecutives\n",
    "    #print(full_splits)\n",
    "    return full_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03e8ea10-e0b9-4c01-bb5a-fd31bece6e90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_piecewise_regression_segments(curve, splits, ax, all_treatment_histories, color = \"blue\", linewidth = 2):\n",
    "    \"\"\"This function is wrapped by piecewise_regression_and_plot below. It plots the actual line segments piecewise\n",
    "    over a rendered cumulative KL Divergence plot. \"\"\"\n",
    "\n",
    "    results_pvals_r2_betas = {}\n",
    "    all_results = []\n",
    "    #for now, just taking the longest treatment history and using that for indexing\n",
    "    full_list_of_histories_all_patients = []\n",
    "    for treatment_history in all_treatment_histories:\n",
    "        for history in treatment_history:\n",
    "             \n",
    "            full_list_of_histories_all_patients.append(tuple(history))\n",
    "    \n",
    "    unique_list_of_histories = list(set(full_list_of_histories_all_patients))\n",
    "    unique_list_of_histories.sort()\n",
    "    \n",
    "    if splits is None:\n",
    "        print(\"No splits to plot!\")\n",
    "        return\n",
    "\n",
    "    #removing any splits of size 7 (too small to be fitted)\n",
    "    removed_splits = [split for split in splits if len(split) > 10]\n",
    "\n",
    "    #setting up subplots \n",
    "    top = len(removed_splits) // 2\n",
    "    bottom = top + (len(removed_splits) % 2)\n",
    "    fig, regression_axes = plt.subplots(2, max(top, bottom), figsize=(20, 20))\n",
    "    fig.suptitle(\"Segments of Non-Diminishing KL Divergence\")\n",
    "    #plt.ylabel(\"KL Divergence (log scale)\")\n",
    "    #plt.xlabel(\"Treatment History\")\n",
    "    \n",
    "    \n",
    "    #len(removed_splits)//2,  len(removed_splits)//2 + len(removed_splits) % 2\n",
    "    \n",
    "    \n",
    "    first_plot_index = 0\n",
    "    all_indices_array = np.arange(0, len(removed_splits))\n",
    "    #print(all_permutations)\n",
    "    \n",
    "    \n",
    "    for i, other_splits in enumerate(removed_splits):\n",
    "        fixed_x_ticks = []\n",
    "        \n",
    "        other_split_start, other_split_end = other_splits[0], other_splits[len(other_splits)-1]\n",
    "        these_x_ticks_unfixed = unique_list_of_histories[other_split_start: other_split_end+1]\n",
    "\n",
    "        #print(len(these_x_ticks_unfixed), other_splits)\n",
    "        for other_i in range(len(other_splits)):\n",
    "            joined_history_piece = \" \".join(str(item)+\" \" for item in these_x_ticks_unfixed[other_i])\n",
    "            \n",
    "            fixed_x_ticks.append(joined_history_piece)\n",
    "        \n",
    "        y_segment = curve[other_split_start: other_split_end + 1] \n",
    "        x_segment = np.arange(other_split_start, other_split_end+1).reshape(-1, 1)\n",
    "        regression_piece = LinearRegression().fit(x_segment, y_segment.reshape(-1, 1))\n",
    "        \n",
    "        y_pred = regression_piece.predict(x_segment)\n",
    "        axis_to_plot_on = regression_axes.flatten()[i]\n",
    "        axis_to_plot_on.scatter(x_segment, y_segment)\n",
    "        axis_to_plot_on.plot(x_segment.flatten(), y_pred.flatten(), color=color, linewidth=linewidth)\n",
    "        axis_to_plot_on.set_ylabel(\"KL Divergence (log scale)\")\n",
    "        axis_to_plot_on.set_xlabel(\"Treatment History\")\n",
    "\n",
    "       \n",
    "        \n",
    "        axis_to_plot_on.set_xticks(x_segment.flatten())\n",
    "        \n",
    "        axis_to_plot_on.set_xticklabels(fixed_x_ticks, fontsize = 7, rotation = 45)\n",
    "\n",
    "        #also returning the report for each segement (including p values for slope) using statsmodels package\n",
    "        x = sm.add_constant(x_segment)\n",
    "        this_model = sm.OLS(y_segment.reshape(-1, 1), x).fit()\n",
    "        slope = this_model.params[1]\n",
    "        pval = this_model.pvalues[1]\n",
    "        r2 = this_model.rsquared\n",
    "\n",
    "        results_pvals_r2_betas[i] = {\n",
    "        \"Segment\": i,\n",
    "        \"Start\": (other_split_start, unique_list_of_histories[other_split_start]),\n",
    "        \"End\": (other_split_end, unique_list_of_histories[other_split_end]),\n",
    "        \"Num Points\": len(y_segment),\n",
    "        \"Slope\": float(slope),\n",
    "        \"p-value\": float(pval),\n",
    "        \"R²\": r2}\n",
    "\n",
    "        all_results.append({\n",
    "        \"Segment\": i,\n",
    "        \"Start\": other_split_start, \"Starting History\": unique_list_of_histories[other_split_start], \n",
    "        \"End\": other_split_end, \"Ending History\": unique_list_of_histories[other_split_end], \n",
    "        \"Num Points\": len(y_segment),\n",
    "        \"Slope\": slope.round(4),\n",
    "        \"p-value\": pval,\n",
    "        \"R²\": r2.round(4)})\n",
    "\n",
    "        \n",
    "        #print(\"for report f{}:\".format(i), this_model.summary())\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df[\"p-value\"] = results_df[\"p-value\"].apply(lambda p: f\"{p:.3e}\" if p < 0.001 else f\"{p:.3f}\")\n",
    "    #print(\"results\", results_df)\n",
    "    results_df.to_csv(\"segment_regression_results.csv\", index=False)\n",
    "    #plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3fed872-9761-48ae-b871-e7e6deb639a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_KLD_spline_and_dKL(already_fitted_spline, deriv_ax, x, observed_KLDs, dy_smooth, x_smooth, n_boot = 300):\n",
    "    \"\"\"Another bootstrap algorithm that computes the 95% CIs of the cumulative KL fitted spline and the derivative of it,\n",
    "    based on the residuals of each of n_boot (parameter above) points of the already fitted spline.\n",
    "    The input x refers to the x values used to fit the spline, the input observed_KLDs refers to the real ones.\n",
    "    Unused - dy_smooth is the smoothed derivative of the already fitted spline\"\"\"\n",
    "    \n",
    "    n_boot = 300\n",
    "    y_boot_preds = []\n",
    "    dy_boot_preds = []\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        # resample residuals\n",
    "        y_fit = already_fitted_spline(x)\n",
    "        residuals = observed_KLDs - y_fit\n",
    "        resampled_y = y_fit + np.random.choice(residuals, size=len(observed_KLDs), replace=True)\n",
    "    \n",
    "        boot_spline = UnivariateSpline(x, resampled_y, s=len(x) * np.var(observed_KLDs) * 0.002)\n",
    "        y_boot_preds.append(boot_spline(x))\n",
    "        dy_boot_preds.append(boot_spline.derivative()(x))\n",
    "    \n",
    "    y_boot_preds = np.array(y_boot_preds)\n",
    "    dy_boot_preds = np.array(dy_boot_preds)\n",
    "    \n",
    "    # Step 1: compute mean derivative across bootstraps\n",
    "    dy_mean = np.mean(dy_boot_preds, axis=0)\n",
    "    \n",
    "    # Step 2: compute deviations from the mean\n",
    "    dy_dev = dy_boot_preds - dy_mean\n",
    "    \n",
    "    # Step 3: compute percentile-based CI of deviations, then recenter around dy_mean\n",
    "    dy_lower = dy_mean + np.percentile(dy_dev, 2.5, axis=0)\n",
    "    dy_upper = dy_mean + np.percentile(dy_dev, 97.5, axis=0)\n",
    "    \n",
    "    # Step 4: plot\n",
    "    #fig, ax = plt.subplots(figsize=(8,5))\n",
    "    deriv_ax.plot(x_smooth, dy_smooth, 'r--', label='Derivative (original fit)')\n",
    "    deriv_ax.fill_between(x, dy_lower, dy_upper, color='red', alpha=0.3, label='95% CI')\n",
    "    deriv_ax.set_xlabel('Treatment index')\n",
    "    deriv_ax.set_ylabel('d(KL)/d(treatment)')\n",
    "    deriv_ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return dy_boot_preds, y_boot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac4e77d-7ddc-48f5-8a0d-709f9ca3eacb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def determine_dy_intervals_subject_to_threshold(deriv_boot_preds, p_val_threshold = .95):\n",
    "    \"\"\"Function to determine if fraction of bootstrap predictions of the derivative of the cumulative KLD curve\n",
    "    exceeds a threshold for a the amount of slopes that should be so.\"\"\"\n",
    "    deriv_boot_preds = np.array(deriv_boot_preds)  # (n_boot, n_points) \n",
    "    \n",
    "    found_indices = []\n",
    "    for i in range(deriv_boot_preds.shape[1]):\n",
    "        fraction_positive = np.mean(deriv_boot_preds[:, i] > 0)\n",
    "        fraction_negative = np.mean(deriv_boot_preds[:, i] < 0)\n",
    "        if fraction_positive >= p_val_threshold or fraction_negative >= p_val_threshold:\n",
    "            found_indices.append(i)\n",
    "\n",
    "    \n",
    "    dy_splits = split_at_non_consecutives(found_indices)\n",
    "    return dy_splits\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e988b2a3-e0a8-49b6-a1df-501709ad1754",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def split_at_non_consecutives(arr):\n",
    "    \"\"\"Simple function to split an array into separate arrays of nonconsecutive points.\"\"\"\n",
    "    if not arr:\n",
    "        return []\n",
    "\n",
    "    result = []\n",
    "    current_sub_array = [arr[0]]\n",
    "\n",
    "    for i in range(1, len(arr)):\n",
    "        # Define \"consecutive\" - here, arr[i] is one greater than arr[i-1]\n",
    "        if arr[i] == arr[i-1] + 1:\n",
    "            current_sub_array.append(arr[i])\n",
    "        else:\n",
    "            result.append(current_sub_array)\n",
    "            current_sub_array = [arr[i]]\n",
    "\n",
    "    result.append(current_sub_array)  # Add the last sub-array\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6ade13b-c258-449b-a2bb-d44ad151d4ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_KL_Divergence_plot(x_vals, kl_divergences, cumulative_kl, splits, all_treatment_histories):\n",
    "    \"\"\"This function plots the Kullback-Leibler Divergence between each consecutive Dirichlet posterior distribution\n",
    "    as a line plot. This is a wrapper of calculate_KL_Divergence_vectorized.\n",
    "    It also plots the cumulative KL Divergence over the KL divergence between individual distributions.\n",
    "    It ends up plotting the linear regression models over the plot as well. \"\"\"\n",
    "   \n",
    "    # Plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    ax1.plot(x_vals[0:], kl_divergences[0:], marker='o', label='KL Divergence')\n",
    "    #ax1.semilogy(x_vals[0:], cumulative_kl[0:], marker='o', linestyle='--', color='orange', label='Cumulative KL Divergence', alpha = .5)\n",
    "\n",
    "\n",
    "    #approximating curve smoothly with spline\n",
    "    #sorting if needed\n",
    "    sorting_indices = np.argsort(x_vals)\n",
    "    x_to_plot = x_vals[sorting_indices]\n",
    "    cumulative_kls_to_plot = cumulative_kl[sorting_indices]\n",
    "\n",
    "    #fitting smoothed spline, smoothing by a factor of the variance and the number of samples\n",
    "    factor_for_smoothing = 0.002\n",
    "    smoothing = len(x_to_plot) * np.var(cumulative_kls_to_plot) * factor_for_smoothing\n",
    "    fitted_spline = UnivariateSpline(x_to_plot, cumulative_kls_to_plot, s = smoothing)\n",
    "\n",
    "    #evaluating the fitted smoothed spline and its derivative\n",
    "    x_smooth = np.linspace(x_to_plot.min(), x_to_plot.max(), 500)\n",
    "    y_smooth = fitted_spline(x_smooth)\n",
    "    dy_smooth = fitted_spline.derivative()(x_smooth)\n",
    "\n",
    "    ax1.plot(x_smooth, y_smooth, 'o', label='Observed cumulative KL', alpha=0.6)\n",
    "    ax1.plot(x_smooth, y_smooth, 'r-', label='Smoothing spline')\n",
    "    ax1.set_xlabel(\"Treatment index\")\n",
    "    ax1.set_ylabel(\"Cumulative KL divergence\")\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    # Secondary axis for derivative\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x_smooth, dy_smooth, 'r--')\n",
    "    ax2.set_ylabel(\"d(KL)/d(treatment)\")\n",
    "    ax2.legend(loc='upper right')    \n",
    "\n",
    "    ax1.set_title('KL Divergence and Cumulative Information Gain (Log Scale)')\n",
    "    ax1.set_xlabel('Treatment History Index')\n",
    "    ax1.set_ylabel('KL Divergence (log scale)')\n",
    "    ax1.legend()\n",
    "    \n",
    "\n",
    "    #plotting the confidence intervals of the spline and its derivative using the bootstrap function above\n",
    "    these_dy_boot_preds, these_y_boot_preds = bootstrap_KLD_spline_and_dKL(fitted_spline, ax2, x_to_plot, cumulative_kls_to_plot, dy_smooth, x_smooth)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    these_determined_splits = determine_dy_intervals_subject_to_threshold(these_dy_boot_preds)\n",
    "    linear_models = plot_piecewise_regression_segments(cumulative_kls_to_plot, these_determined_splits, ax1, all_treatment_histories, linewidth = 1)\n",
    "\n",
    "    #mental note: just need to collect the p values for the fit segments, Dubin Watson statistic for autocorrelation, maybe a bootstrap CI\n",
    "    #if not just use the confidence interval spit out by the linear model fitting module above (use chatgpt thread)\n",
    "    \n",
    "    return x_vals, np.log(cumulative_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f89b4226-a9a9-4df1-b778-fee02135b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parsing(data_filename):\n",
    "    \"\"\"Function that does the data parsing, given a csv filename in the same directory.\"\"\"\n",
    "    raw_data = pd.read_csv(data_filename)\n",
    "\n",
    "    #actual implementation\n",
    "\n",
    "    this_seperate_DFs, this_intro_days = seperate_patients(raw_data)\n",
    "    #this_inspected_data = display_plots_of_dataset(this_seperate_DFs, this_intro_days, .1) #for inspection\n",
    "    this_md_DFs, this_treatment_history = add_history_metadata(this_seperate_DFs, this_intro_days)\n",
    "    these_states, these_ranges = find_and_plot_severity_states(this_md_DFs)\n",
    "    these_assigned_md_DFs = assign_states_to_mdfs(this_md_DFs, these_states, these_ranges)\n",
    "\n",
    "    return this_treatment_history, these_assigned_md_DFs, these_states, these_ranges, this_md_DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6597df55-3c8b-4e3b-a938-fb15a8ce4122",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_visualization(these_assigned_md_DFs, this_treatment_history, this_md_DFs, these_ranges):\n",
    "    \"\"\"Function that actually plots all relevant plots for the observed data.\"\"\"\n",
    "    these_checked_CIs = check_confidence_intervals(this_md_DFs, these_ranges) #returns a dictionary now\n",
    "    \n",
    "    built_histograms, raw_probabilities = build_histograms(these_assigned_md_DFs)\n",
    "\n",
    "    plotted_histogram = plot_histograms(raw_probabilities)\n",
    "    \n",
    "    uninformative_prior = [1,1,1] #with a1 corresponding to low severity, a2 corresponding to medium, and a3 corresponding to high\n",
    "    \n",
    "    these_Dirichlets, these_categories = build_Dirichlet(uninformative_prior, built_histograms)\n",
    "    \n",
    "    dirichlet_credible_intervals = plot_Dirichlets_credible_interals(these_Dirichlets, these_categories)\n",
    "    \n",
    "    these_xs, this_log_cum_kls, this_kls = calculate_KL_Divergence_vectorized(these_Dirichlets)\n",
    "    splits = split_for_piecewise_regression(these_xs, this_log_cum_kls)\n",
    "    final_plot = make_KL_Divergence_plot(these_xs, this_log_cum_kls, this_kls, splits, this_treatment_history)\n",
    "\n",
    "    return these_Dirichlets, these_categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6d4b5f1-be9b-4103-a94b-e45f3c3e7258",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def model_building(these_assigned_md_DFs):\n",
    "    \"\"\"Function that contains all of the models fit to the observed data.\"\"\"\n",
    "    this_fit_model = fit_predictive_linear_regression_model_of_severity(these_assigned_md_DFs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a04df51-3bbd-4c16-913c-7ae1312f15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predictive_linear_regression_model_of_severity(metadata_dfs):\n",
    "    \"\"\"Function to fit a predictive linear model of acne severity as a function of: \n",
    "    1) Lagged/previous day's severity; 2/3) Cumulative days of the current treatment (in this case, either antibiotics or cream)\n",
    "    4) Synergistic effect of cream being followed by a certain number of days of antibiotics.\n",
    "    5) Saturation function based on the Michaelis-Menten half saturation constant (particuarly as cream eventually causes the molecular system\n",
    "    of skin cells to approach homeostasis, with its effect progressively leveling off.\"\"\"\n",
    "    \n",
    "    day_and_sev = defaultdict(list)\n",
    "    cream_saturation_constant = 12 #this hyperparameter can be changed as the model learns, at this time it's about half of the cream treatment block\n",
    "    \n",
    "    for metadata_df in metadata_dfs:\n",
    "        for i, row in metadata_df.iterrows():\n",
    "            last_severity = 0 #fix this later to be average baseline\n",
    "            current_history = tuple(row[\"treatment_history\"])\n",
    "\n",
    "\n",
    "            #4 variables - days of current antibiotics, days of current cream, cumulative cream/antibiotic effect, saturation function\n",
    "            #unpacking history to get the relevant pieces, saving as keys\n",
    "            current_treatment = current_history[len(current_history)-1][0]\n",
    "            days_current_treatment = current_history[len(current_history)-1][1]\n",
    "            #finding days of antibiotics if following cream\n",
    "            days_of_current_antibiotics = 0\n",
    "            days_of_current_cream = 0 \n",
    "            antibiotics_cream_interaction = 0\n",
    "            saturation_function_output = 0\n",
    "            \n",
    "            if current_treatment == \"Antibiotics\": #at some point this can be changed away from hardcoding\n",
    "                days_of_current_antibiotics = days_current_treatment\n",
    "                if len(current_history) != 1: #ie, not the first treatment in a series\n",
    "                    last_treatment = current_history[len(current_history)-2][0]\n",
    "                    if last_treatment == \"Cream\": #this part gives syngergistic effect of antibiotics used after cream\n",
    "                        previous_cream_days = current_history[len(current_history)-2][1]\n",
    "                        #simple linear function of the days of antibiotics giving the antibiotics_cream_interaction\n",
    "                        antibiotics_cream_interaction = previous_cream_days * days_of_current_antibiotics \n",
    "                       \n",
    "            if current_treatment == \"Cream\":\n",
    "                days_of_current_cream = days_current_treatment\n",
    "                saturation_function_output = days_of_current_cream/(cream_saturation_constant + days_of_current_cream)\n",
    "\n",
    "            current_severity = row[\"AcneSeverity\"]\n",
    "            model_contributions = ({\"days_of_current_antibiotics\": days_of_current_antibiotics, \"days_of_current_cream\": days_of_current_cream,\n",
    "                             \"antibiotics_cream_interaction\": antibiotics_cream_interaction, \"saturation_function_output\": saturation_function_output}, \n",
    "                                  last_severity, current_severity)\n",
    "            \n",
    "            day_and_sev[current_history].append(model_contributions)\n",
    "            last_severity = current_severity\n",
    "\n",
    "    #saving the independent variable values per history to a dataframe for easier fitting to the multivariate regression model\n",
    "    rows = []\n",
    "    for history, entries in day_and_sev.items():\n",
    "        #print(entries)\n",
    "        for features, previous_sev, curr_sev in entries:\n",
    "            delta = curr_sev - previous_sev\n",
    "            row = features.copy()\n",
    "            row['delta_severity'] = delta\n",
    "            row['treatment_history'] = str(history) \n",
    "            rows.append(row)\n",
    "    \n",
    "    dataframe_for_fitting = pd.DataFrame(rows)\n",
    "    history_vectors_of_independent_vars = dataframe_for_fitting[['days_of_current_antibiotics', 'days_of_current_cream',\n",
    "        'antibiotics_cream_interaction', 'saturation_function_output']]\n",
    "    history_vectors_of_independent_vars = sm.add_constant(history_vectors_of_independent_vars) #adding constant term\n",
    "    severity_change = dataframe_for_fitting[\"delta_severity\"]\n",
    "\n",
    "    fitted_model = sm.OLS(severity_change, history_vectors_of_independent_vars).fit()\n",
    "    print(fitted_model.summary())\n",
    "\n",
    "    #mental note: finished model fitting. \n",
    "    #now, print the gradient of the model and the obtained betas. Use this, and the simulation code that chatgpt \n",
    "    #gave to show the significance of the model, and how different treatment plans can be input to find the expected severity\n",
    "    #change\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b34bb0-a6b9-4949-8b43-881932592655",
   "metadata": {},
   "source": [
    "\\documentclass{article}\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amsfonts}\n",
    "\\usepackage{amssymb}\n",
    "\\begin{document}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee59d00-1407-458b-a723-60a2054a6bb5",
   "metadata": {},
   "source": [
    "The predictive model that is built is of the form:\n",
    "\n",
    "\n",
    "Latent State Vector: \n",
    "$$\n",
    "\\mathbf{acne \\,state} = \\begin{pmatrix}\n",
    "B_t \\\\\n",
    "I_t \\\\\n",
    "S_t\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Where $B_t$ refers to bacterial facial load at time t, $I_t$ refers to inflammatory activity load at time t, $S_t$ refers to sebum production at time t. \n",
    "\n",
    "They evolve according to - \n",
    "$$B_t = B_{t-1} + r_{growth} \\cdot B_{t-1}\\frac{1-B_{t-1}}{K_{CC}}-k_{antibiotics} \\cdot days_{antibiotics} \\cdot B_{t-1} -k_{cream} \\cdot C(days_{cream})+ noise$$\n",
    "$$I_t = I_{t-1} + I_{bacterial \\, induction} \\cdot B_{t-1} - I_{decay}/T(tstd)\\cdot T(tstd) - I_{baseline decay} \\cdot I_{t-1} + noise$$\n",
    "$$S_t = S_{t-1} + r_{I production} \\cdot I_{t-1} -r_{cream \\, clean} \\cdot cream \\, used + noise$$\n",
    "\n",
    "\n",
    "Where $r_{growth}$ refers to the growth constant of acne causing bacteria, $K_{CC}$ refers to their carrying capacity, $k_{antibiotics}$ refers to the antibiotic's action rate constant, $I_{bacterial \\, induction}$ refers to the rate of inflammation induced by bacterial load, $I_{decay}/tstd$ refers to the proportionality constant between inflammation reduction and cumulative treatment effect, $T(ttsd)$. \n",
    "\n",
    "$T(tstd)$ refers to the cumulative treatment effect of a given treatment history (referred to here as treatment series to date, tstd). T(tstd) is calculated as the expected acne severity change over the Dirichlet posterior distribution corresponding to the last day in the treatment series to date, that is:\n",
    "\n",
    "$T(tstd) = \\mathbb{E}(\\Delta Severity \\mid ttsd)$ \n",
    "\n",
    "$r_{I production} $ refers to the rate of inflammation increase given active inflammation, $r_{cream \\, clean}$ refers to the amount of mechanical sebum removal that the cream causes. \n",
    "\n",
    "The state vector evolves according to:\n",
    "$$\n",
    "acne \\, state_{t} = Av_{t-1} + B(tstd_{\\,day\\,t-1}) + w_{t-1}\n",
    "$$\n",
    "\n",
    "And the acne severity (scalar) evolves according to:\n",
    "$$\n",
    "severity_{t} = Cacne \\, state_{t} + m_{t-1}\n",
    "$$\n",
    "\n",
    "Where $w_{t-1}$ and $m_{t-1}$ are normally distributed noise terms with means 0 and standard deviations R and Q. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d8ce21b-86ef-42ba-b8f7-afec8d847419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         delta_severity   R-squared:                       0.447\n",
      "Model:                            OLS   Adj. R-squared:                  0.445\n",
      "Method:                 Least Squares   F-statistic:                     225.5\n",
      "Date:                Thu, 06 Nov 2025   Prob (F-statistic):          7.84e-142\n",
      "Time:                        18:10:42   Log-Likelihood:                -4531.5\n",
      "No. Observations:                1120   AIC:                             9073.\n",
      "Df Residuals:                    1115   BIC:                             9098.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                           -80.5126      1.088    -73.982      0.000     -82.648     -78.377\n",
      "days_of_current_antibiotics      -0.6543      0.076     -8.611      0.000      -0.803      -0.505\n",
      "days_of_current_cream             1.5994      0.187      8.548      0.000       1.232       1.967\n",
      "antibiotics_cream_interaction    -0.0055      0.003     -2.163      0.031      -0.010      -0.001\n",
      "saturation_function_output      -27.5793      6.896     -3.999      0.000     -41.110     -14.048\n",
      "==============================================================================\n",
      "Omnibus:                       48.552   Durbin-Watson:                   1.588\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               58.859\n",
      "Skew:                           0.456   Prob(JB):                     1.66e-13\n",
      "Kurtosis:                       3.657   Cond. No.                     3.89e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.89e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "def main(this_raw_data_name):\n",
    "    data_returns = data_parsing(this_raw_data_name)\n",
    "\n",
    "    this_built_model = model_building(data_returns[1])\n",
    "    \n",
    "    view_plots = False\n",
    "    # user_input = input(\"Do you want to view the data? Type Yes or No.\")\n",
    "    \n",
    "    # if user_input == \"Yes\":\n",
    "    #     view_plots = True\n",
    "    # if view_plots:\n",
    "        \n",
    "    #     this_data_visualization = data_visualization(data_returns[1], data_returns[0], data_returns[4], data_returns[3])\n",
    "    # if not view_plots:\n",
    "    #     print(\"Ok, going on to modeling.\")\n",
    "\n",
    "#retrieving Acne04 dataset from Kaggle source (local download on machine)\n",
    "this_raw_data_name = \"archive (2)/sim_acne.csv\"\n",
    "if __name__ == \"__main__\":\n",
    "    main(this_raw_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe18978-0755-4994-89fb-8a9be44adf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27484e4b-a5be-492b-bd50-a9d4c87ffc4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_piecewise_regression_and_plot_unused(points, splits):\n",
    "    \"\"\"This function actually splits a given array (here, cumulative KL divergence) into seperate regression models,\n",
    "    using splits to partition the array and then fit a linear regression model to each one.\n",
    "    It then calls plot_piecewise_regression_segments to plot the segments over the cumulative KL divergence Curve. Unused in this version.\"\"\"\n",
    "    split_points_and_indices = [(points[split[0]:split[1]+1], split) for split in splits]\n",
    "    linear_model = LinearRegression()\n",
    "    consecutive_models = [LinearRegression().fit(np.arange(len(one_split_points[0])).reshape(-1, 1),one_split_points[0].reshape(-1, 1))for one_split_points in split_points_and_indices]\n",
    "\n",
    "    slopes = [which_model.coef_[0] for which_model in consecutive_models]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17f992a3-b068-4e7e-9bb4-0ebdf84ca2de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def old_build_histograms(metadata_DFs):\n",
    "    \"\"\"Unused in this version. Will condition distributions on previous state and treatment history. Stay tuned... \n",
    "    \n",
    "    \n",
    "    1) The algorithm iterates over all patient's severity dataframe and, for each... \n",
    "    \n",
    "    Uses the metadata column to build an actual sequence of treatments for each patient along with the state at each. \n",
    "    It does this by pulling the treatment history column for each dataset as well as the states, both as lists. Then, it uses a default dict to\n",
    "    count the occurences of transition from state to state for the current treatment and the one before it. In other words, a dictionary\n",
    "    of dictionaries is returned, where the keys are the treatments in order of occurence, and the values are dictionaries of counts \n",
    "    for each state in the treatment order. \n",
    "    \n",
    "    This amounts to a context-dependent conditional model of acne treatement severity. \n",
    "    \n",
    "    A context-dependent First Order Markov Model is also built in the second loop, using instead a tuple of the previous state and preivous \n",
    "    treatment as a key in the default dictionary. \n",
    "    \n",
    "    2) Then, histograms of the context-dependent conditional model of acne treatment severity are plotted. After this, a 3 State visual\n",
    "    Markov Model is generated for the 1st order Markov Model. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_state_counts = defaultdict(Counter)\n",
    "    #all_transition_counts_second_order = defaultdict(Counter)\n",
    "    \n",
    "    for i, patient_df in enumerate(metadata_DFs):\n",
    "        histories = patient_df[\"treatment_history\"].values\n",
    "        states = patient_df[\"State\"].values\n",
    "\n",
    "        \n",
    "        \n",
    "        for state_index in range(1, len(states)):\n",
    "            current_state = states[state_index] #state at position state_index in the patient's dataframe\n",
    "            #previous_history = histories[state_index - 1] #metadata (treatment history) at position state_index - 1 in the patient's dataframe\n",
    "            current_history = histories[state_index] #metadata (treatment history) at position state_index  in the patient's dataframe\n",
    "            current_history_key = tuple((str(treatment), int(days)) for treatment, days in current_history)\n",
    "           \n",
    "            \n",
    "            #previous_treatment = previous_history[-1][0] #previous treatment right before position state_index\n",
    "            #current_treatment = current_history[-1][0] #current treatment at state_index\n",
    "    \n",
    "            #recording the actual counts of severities, with the context of the prior treatment as the key\n",
    "            all_state_counts[current_history_key][current_state] += 1\n",
    "            \n",
    "        \n",
    "        #doing the same for the First order Markov Chain (UNUSED)\n",
    "        # for state_index in range(2, len(states)):\n",
    "        #     last_state = states[state_index - 1] \n",
    "        #     this_current_state = states[state_index] #state at position state_index in the patient's dataframe\n",
    "        #     this_previous_history = histories[state_index - 1] #metadata (treatment history) at position state_index - 1 in the patient's dataframe\n",
    "            \n",
    "        #     this_current_history = histories[state_index] #metadata (treatment history) at position state_index  in the patient's dataframe\n",
    "        #     this_previous_treatment = this_previous_history[-1][0] #previous treatment right before position state_index\n",
    "        #     this_current_treatment = this_current_history[-1][0] #current treatment at state_index\n",
    "    \n",
    "        #     this_key = (this_previous_treatment, last_state)\n",
    "        #     #recording the actual counts of severities, with the context of the prior treatment as the key\n",
    "        #     all_transition_counts_second_order[this_key][current_state] += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "    #normalizing counts dictionaries into distributions\n",
    "    first_order_probabilities = {}\n",
    "    second_order_probabilities = {}\n",
    "    \n",
    "    for previous_treatment, state_counts in all_state_counts.items():\n",
    "        total_counts  = sum(state_counts.values())\n",
    "        probabilities_given_previous_state = {state: count/total_counts for state, count in state_counts.items()}\n",
    "        first_order_probabilities[previous_treatment] = probabilities_given_previous_state\n",
    "        \n",
    "        \n",
    "    # for (previous_treatment, previous_state), state_counts in all_transition_counts_second_order.items(): (UNUSED)\n",
    "    #     total_counts  = sum(state_counts.values())\n",
    "    #     probabilities_given_previous_state = {state: count/total_counts for state, count in state_counts.items()}\n",
    "    #     second_order_probabilities[(previous_treatment, previous_state)] = probabilities_given_previous_state\n",
    "\n",
    "    print(all_state_counts)\n",
    "\n",
    "    return (all_state_counts, first_order_probabilities) #, (all_transition_counts_second_order, second_order_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
